{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825bcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd7ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    return html_content\n",
    "\n",
    "def find_url_in_comments(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        match = re.search(r'https?://\\S+', comment)\n",
    "        if match:\n",
    "            return match.group()\n",
    "    return None\n",
    "\n",
    "def parse_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25020255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r'D:\\github\\garage\\02_linkedin\\download\\\\'\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.html'):\n",
    "        print(file)\n",
    "        file_path = path + file\n",
    "        \n",
    "        html_content = read_html_file(file_path)\n",
    "        link = find_url_in_comments(html_content)[:-1]\n",
    "        soup = parse_html(html_content)\n",
    "        \n",
    "        name = soup.find('h1', {'class': 'text-heading-xlarge inline t-24 v-align-middle break-words'}).text.strip()\n",
    "\n",
    "        try:\n",
    "            headline = soup.find('div', {'class': 'text-body-medium break-words'}).text.strip()\n",
    "        except:\n",
    "            headline = None\n",
    "        try:\n",
    "            place = soup.find('span', {'class': 'text-body-small inline t-black--light break-words'}).text.strip()\n",
    "        except:\n",
    "            place = None\n",
    "        try:\n",
    "            company_link = soup.find('a', {'data-field': 'experience_company_logo'})['href']\n",
    "        except:\n",
    "            company_link = None\n",
    "        try:\n",
    "            company_name = soup.find('span', {\n",
    "                'class': 'GrpjSuTnJuVIZvqQGOlBpxLRnnyFpfCYJCw hoverable-link-text break-words text-body-small t-black'}).text.strip()\n",
    "        except:\n",
    "            company_name = None\n",
    "        try:\n",
    "            position = soup.find('div', {'class': 'display-flex flex-wrap align-items-center full-height'}).text.strip()\n",
    "        except:\n",
    "            position = None\n",
    "        try:\n",
    "            education = soup.find('span', {\n",
    "                'class': 'pv-text-details__right-panel-item-text hoverable-link-text break-words text-body-small t-black'}).text.strip()\n",
    "        except:\n",
    "            education = None\n",
    "\n",
    "        profile_data = {\n",
    "            'link': link,\n",
    "            'name': name,\n",
    "            'headline': headline,\n",
    "            'place': place,\n",
    "            'company_link': company_link,\n",
    "            'company_name': company_name,\n",
    "            'position': position,\n",
    "            'education': education,\n",
    "        }\n",
    "\n",
    "        data.append(profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9eb962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62acb160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6bf8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('profiles.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3565479a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_links_list(profile_links_path, profiles_path):\n",
    "    new_links = pd.read_csv(profile_links_path, usecols=['link'])\n",
    "\n",
    "    if os.path.isfile(profiles_path):\n",
    "        old_links = pd.read_csv(profiles_path, usecols=['link', 'name'])\n",
    "        old_links.dropna(inplace=True)\n",
    "    else:\n",
    "        old_links = []\n",
    "\n",
    "    return new_links.loc[~new_links['link'].isin(old_links['link']), 'link']\n",
    "\n",
    "profile_links_path = 'profile_links_clean.csv'\n",
    "profiles_path = 'profiles.csv'\n",
    "links = get_links_list(profile_links_path, profiles_path)\n",
    "\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1c366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(links.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee163fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.to_csv('remain_links.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
